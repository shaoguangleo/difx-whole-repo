#!/usr/bin/env bash
#===========================================================================
# Copyright (C) 2021  Max-Planck-Institut f√ºr Radioastronomie, Bonn, Germany
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#===========================================================================
# SVN properties (DO NOT CHANGE)
#
# $Id$
# $HeadURL$
# $LastChangedRevision$
# $Author$
# $LastChangedDate$
#
#============================================================================

# Shell script to allow starting of heterogeneous DiFX jobs through the SLURM batch scheduler.
# DiFX jobs will be heterogeneous when containing e.g. mark5 and/or mark5 playback units or
# if a specific head node is required.
# The "normal" SLURM mechanism of using jobsteps is unsuited as it will always execute in 
# exclusive mode when using jobsteps which will prevent starting of multiple DiFX jobs in
# parallel.
# Execute with startdifx -A difxslurm ...
#============================================================================

# make sure salloc is started in background
set -m

# make sure slurm job gets canceled on SIGINT
trap cleanExit SIGINT

JOB_ID=""
PID=""

function cleanExit {
    if [[ -n "$JOB_ID" ]]; then
      scancel $JOB_ID
    fi
    kill -9 $PID >& /dev/null
    echo "done"
    exit
}

path=`dirname $1`
job=`basename $1`


# Specific settings (adjust for your cluster)
partition=correlator
threads=19

cd $path

if [ ! -f $job.input ]; then
    echo "ERROR: $job.input does not exist"
    exit 2 
fi
if [ ! -f $job.machines ]; then
    echo "ERROR: $job.machines does not exist"
    exit 2 
fi
# Determine required resources
# Each thread can roughly do 85Mbps
# speedup = scanDuration / correlationDuration  
# np = numDS * dataRate * speedup / 85

out=`difxresource -r 85 --all $job.input | tail -1`

if [[ $out =~ ^([0-9])/([0-9]+)/([0-9]+) ]]; 
then 
  numDS=${BASH_REMATCH[2]}
  np=${BASH_REMATCH[3]}
else 
  echo "ERROR: difxresource illegal output format ($out). Exiting"; 
  exit 2 
fi
nodes=$(((np+threads-1)/threads))
#echo $np $nodes

# generate .machine file (datastreams only)
head -n $((numDS+=1)) $job.machines > $job.dsmachines

# parse the .dsmachines file and
# contruct slurm jobsteps
# for all datastream processes
jobsteps=""
mkfifo mypipe
sort $job.dsmachines | uniq -c > mypipe &

while read count node
do
   jobsteps+=" -p $partition --ntasks=$count --nodes=1 --nodelist=$node :"
   #echo    $count $node
done < mypipe
rm mypipe

jobsteps="${jobsteps::-1}"
stepcount=`echo $jobsteps | tr -cd ':' | wc -c | tr -d ' '`
((stepcount++))


#echo $np
#echo $jobsteps

echo "Using $nodes compute nodes with $threads threads to process this job"

#write the slurm batch file
#echo "HOSTFILE=$job.machines" > $job.slurm
#echo "cat $job.dsmachines > \$HOSTFILE" >> $job.slurm
#echo "srun --pack-group=$stepcount hostname -s >> \$HOSTFILE" >> $job.slurm
#echo "numtasks=\`cat \$HOSTFILE | wc -l\`" >> $job.slurm
#echo "mpirun -np \$numtasks --hostfile \$HOSTFILE $DIFX_MPIRUNOPTIONS /cluster/difx/runmpifxcorr.$DIFX_VERSION $job.input" >> $job.slurm
#chmod u+x $job.slurm
#

# construct the hostfile
HOSTFILE=$job.machines
cat $job.dsmachines > $HOSTFILE
cnodes=`srun -p correlator --constraint=compute --cpus-per-task=$threads --ntasks-per-node=1 --nodes=$nodes  hostname -s`

cnodelist=`echo $cnodes | sed 's/ /,/g'`
echo $cnodes | sed 's/ /\n/g' >> $HOSTFILE

numtasks=`cat $HOSTFILE | wc -l`

rm -f /tmp/$job
# make dummy allocation
#echo salloc -J $job $jobsteps : -p correlator --cpus-per-task=$threads --ntasks-per-node=1 --nodelist=$cnodelist
salloc -J $job $jobsteps : -p correlator --cpus-per-task=$threads --ntasks-per-node=1 --nodelist=$cnodelist &> /tmp/$job &
#echo $jobsteps

sleep 1
# get pid of salloc process
PID=$!

# parse salloc output to see whether resources have been granted
# salloc: job 10912 queued and waiting for resources
regPending='salloc: Pending job allocation ([0-9]+)'
regGrant='salloc: Granted job allocation ([0-9]+)'
#regQueue='salloc: job ([0-9]+) queued'
regRevoked='salloc: Job allocation ([0-9]+) has been revoked'
START=0
echo "Waiting for SLURM resource allocation"
while [ $START -eq 0 ]
do
    while read l; do
        
        # obtain job ID from pending message
        if [[ $l =~ $regPending ]]; then
            JOB_ID=${BASH_REMATCH[1]}
            echo $JOB_ID > $job.slurmid
            echo "JOBID: " $JOB_ID
        fi
        # allocation granted
        if [[ $l =~ $regGrant ]]; then
            if [[ $JOB_ID == ${BASH_REMATCH[1]} ]]; then
              echo "Allocation granted"
              START=1
              break
            fi
        fi
        # in case of error the allocation will be revoked
        if [[ $l =~ $regRevoked ]]; then
              break 2
        fi 
        
    done < /tmp/$job
done

if [[ START == 1 ]]; then 
  echo "Granted job allocation" $JOB_ID
  mpirun -np $numtasks --hostfile $HOSTFILE $DIFX_MPIRUNOPTIONS /cluster/difx/runmpifxcorr.$DIFX_VERSION $job.input
else
  cat /tmp/$job
fi

cleanExit

